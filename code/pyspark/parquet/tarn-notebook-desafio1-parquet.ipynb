{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "90df9259",
   "metadata": {},
   "source": [
    "# Bootcamp da Xpe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0676d49b",
   "metadata": {},
   "source": [
    "## Engenharia de Dados em Cloud"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b99938bb",
   "metadata": {},
   "source": [
    "### Módulo 1: Fundamentos em Arquitetura de Dados e Soluções em Nuvem\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "acfda5eb",
   "metadata": {},
   "source": [
    "### Objetivos:\n",
    ">> Implementação de um Data Lake; <br>\n",
    ">> Armazenamento de dados em Storage camada Raw; <br>\n",
    ">> Armazenamento de dados em Storage camada Bronze; <br>\n",
    ">> Armazenamento de dados em Storage camada Silver; <br>\n",
    ">> Implementação de Processamento de Big Data; <br>\n",
    ">> IaC de toda estrutura com Terraform; <br>\n",
    ">> Esteiras de Deploy com Github. <br>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "76ae8fc5",
   "metadata": {},
   "source": [
    "### Esse notebook trata dos itens 2 e 3 do desafio\n",
    "2. Realizar tratamento no dataset da RAIS 2020  <br>\n",
    "    a. Modifique os nomes das colunas, trocando espaços por “_”; <br>\n",
    "    b. Retire acentos e caracter especiais das colunas; <br>\n",
    "    c. Transforme todas as colunas em letras minúsculas; <br>\n",
    "    d. Crie uma coluna “uf” através da coluna \"municipio\"; <br>\n",
    "    e. Realize os ajustes no tipo de dado para as colunas de remuneração.\n",
    "\n",
    "3. Transformar os dados no formato parquet e escrevê-los na zona staging ou zona silver do seu Data Lake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44c0e6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "# import pyarrow\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit, input_file_name, regexp_replace\n",
    "from pyspark.sql import functions as spkFn\n",
    "\n",
    "import unicodedata\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "75287e6d",
   "metadata": {},
   "source": [
    "#### Inicia uma `Session` do Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcdf7629",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession.builder\n",
    "                     .appName(\"readFile\")\n",
    "                     .config(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "                     .getOrCreate()) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e2ef816",
   "metadata": {},
   "source": [
    "#### Path para diretório source e target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70c0fc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "productRais = \"RAIS2020\"\n",
    "\n",
    "#### Path Cloud AWS\n",
    "# pathRaw     = f\"C:/aws/bucket_dow_up/data_up/{productRais}/\"\n",
    "# pathBronze  = f'C:/aws/dados/dados_bronze/{productRais}/parquet/'\n",
    "\n",
    "#### Path Load\n",
    "pathRaw    = f\"D:/{productRais}/DATA_GZIP/\"\n",
    "pathBronze = f\"D:/{productRais}/bronze/DATA_PARQUET/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c2f7ff43",
   "metadata": {},
   "source": [
    "#### Schema DDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cf90e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileNameSchema = \"RAIS_VINC_PUB_NORTE.txt.gz\"\n",
    "filePathSchema = f\"{pathRaw}/{fileNameSchema}\"\n",
    "\n",
    "fileDfSchema   = (spark.read\n",
    "                       .format(\"csv\")\n",
    "                       .option(\"header\",\"true\")\n",
    "                       .option(\"sep\", \";\")\n",
    "                       .option(\"encoding\", \"latin1\")\n",
    "                       .option(\"inferSchema\", \"true\")\n",
    "                       .load(filePathSchema)\n",
    "                       .schema)\n",
    "\n",
    "schemaJson     = fileDfSchema.json()\n",
    "schemaDDL      = spark.sparkContext._jvm.org.apache.spark.sql.types.DataType.fromJson(schemaJson).toDDL()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba09e753",
   "metadata": {},
   "source": [
    "#### Ler arquivos com a API DataFrameRead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c496cb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read\n",
    "rais2020_csv = (spark.read\n",
    "                     .format(\"csv\")\n",
    "                     .option(\"header\",\"true\")\n",
    "                     .option(\"sep\", \";\")\n",
    "                     .option(\"encoding\", \"latin1\")\n",
    "                     .option(\"inferSchema\", \"true\")\n",
    "                     .schema(schemaDDL)\n",
    "                     .load(pathRaw)\n",
    "                     .withColumn(\"file_name\", lit(input_file_name())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b721058c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(rais2020_csv.printSchema())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "614643f0",
   "metadata": {},
   "source": [
    "### Funções para normalizar as colunas\n",
    "\n",
    "> ***normalizar_colunas***\n",
    "1. Função para normalizar as colunas de um dataframe\n",
    "    - Retira espaços vazios e incluir um underline (Ex: `Sobre Nome -> Sobre_Nome`)\n",
    "    - Retira ponto e incluir um underline (Ex: `Sobre.Nome -> Sobre_Nome`)\n",
    "    - Formata todas as colunas com letras minúsculas (Ex: `Sobre_Nome -> sobre_nome`)\n",
    "\n",
    "> ***normalizar_acentos***\n",
    "2. Função para retirar os acentos de todas as colunas de um dataframe\n",
    "    - Remover espaços nas extremidades (Ex: `\"  sobre_nome  \" -> \"sobre_nome\"`)\n",
    "    - Replace de carácteres especiais por underline (Ex: `sobre@nome -> sobre_nome`)\n",
    "    - Remover underlines nas extremidades (Ex: `_sobre_nome_ -> sobre_nome`)\n",
    "    - Remover acentuação (Ex: `média_mês -> media_mes`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "708a3e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Função para normalizar as colunas de um dataframe\n",
    "def normalizar_colunas(df):\n",
    "  try:\n",
    "    new_column_spaces_lower = (list(map(lambda x: x.replace(\" \", \"_\")\n",
    "                                                   .replace(\".\", \"_\")\n",
    "                                                   .lower(),\n",
    "                                                 df.columns)))\n",
    "    return df.toDF(*new_column_spaces_lower) \n",
    "  except Exception as err:\n",
    "        error_message = f\"Erro ao normalizar nomes das colunas: {str(err)}\"\n",
    "        print(error_message)\n",
    "        raise ValueError(error_message)\n",
    "\n",
    "## Função para retirar os acentos de todas as colunas de um dataframe\n",
    "def normalizar_acentos(str):\n",
    "  try:\n",
    "    new_str = str\n",
    "    # Remover espaços nas extremidades\n",
    "    new_str = new_str.strip()\n",
    "    # Replace de carácteres especiais por underline\n",
    "    new_str = re.sub(r\"[^\\w]\", \"_\", new_str)\n",
    "    # Remover underlines nas extremidades\n",
    "    new_str = new_str.strip(\"_\")\n",
    "    # Remover 2 underlines juntos e deixar apenas 1\n",
    "    new_str = new_str.replace(\"__\", \"_\")\n",
    "    # Remover acentuação\n",
    "    new_str = unicodedata.normalize('NFKD', new_str)\n",
    "    new_str = u\"\".join([c for c in new_str if not unicodedata.combining(c)])\n",
    "    return new_str\n",
    "  except Exception as err:\n",
    "    error_message = f\"Erro ao normalizar nomes das colunas: {str(err)}\"\n",
    "    print(error_message)\n",
    "    raise ValueError(error_message)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a02687b",
   "metadata": {},
   "source": [
    "#### Utiliza as funções no Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "767ae65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "renamed_df = normalizar_colunas(rais2020_csv)\n",
    "\n",
    "rais2020_renamed = renamed_df.select([spkFn.col(col).alias(normalizar_acentos(col)) for col in renamed_df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f8fcfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(rais2020_renamed.printSchema())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d892fc35",
   "metadata": {},
   "source": [
    "#### Normalização das colunas de remuneração e outras\n",
    "> - As colunas de `remuneração` <br>\n",
    "    - Utiliza a função `regexp_replace` para fazer um replace de `,` ***vírgula*** para `.` ***ponto*** <br>\n",
    "    - Converte para o tipo de dado `double`\n",
    "    \n",
    "- Cria a coluna `ano` com a informação do ano do dataset\n",
    "- Cria a coluna `uf` com os dois primeiro caracteres da coluna `municipio` e converte para o tipo de dado `inteiro`\n",
    "- Converte a coluna `mes_desligamento` para o tipo de dado `inteiro`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffa44194",
   "metadata": {},
   "outputs": [],
   "source": [
    "rais2020_fim = (\n",
    "                 rais2020_renamed\n",
    "                        .withColumn(\"ano\", lit(\"2020\").cast('int'))\n",
    "                        .withColumn(\"uf\", col(\"municipio\").cast('string').substr(1,2).cast('int'))\n",
    "                        .withColumn(\"mes_desligamento\", col('mes_desligamento').cast('int'))\n",
    "                        .withColumn(\"vl_remun_dezembro_nom\", regexp_replace(\"vl_remun_dezembro_nom\", ',', '.').cast('double'))\n",
    "                        .withColumn(\"vl_remun_dezembro_sm\", regexp_replace(\"vl_remun_dezembro_sm\", ',', '.').cast('double'))\n",
    "                        .withColumn(\"vl_remun_media_nom\", regexp_replace(\"vl_remun_media_nom\", ',', '.').cast('double'))\n",
    "                        .withColumn(\"vl_remun_media_sm\", regexp_replace(\"vl_remun_media_sm\", ',', '.').cast('double'))\n",
    "                        .withColumn(\"vl_rem_janeiro_sc\", regexp_replace(\"vl_rem_janeiro_sc\", ',', '.').cast('double'))\n",
    "                        .withColumn(\"vl_rem_fevereiro_sc\", regexp_replace(\"vl_rem_fevereiro_sc\", ',', '.').cast('double'))\n",
    "                        .withColumn(\"vl_rem_marco_sc\", regexp_replace(\"vl_rem_marco_sc\", ',', '.').cast('double'))\n",
    "                        .withColumn(\"vl_rem_abril_sc\", regexp_replace(\"vl_rem_abril_sc\", ',', '.').cast('double'))\n",
    "                        .withColumn(\"vl_rem_maio_sc\", regexp_replace(\"vl_rem_maio_sc\", ',', '.').cast('double'))\n",
    "                        .withColumn(\"vl_rem_junho_sc\", regexp_replace(\"vl_rem_junho_sc\", ',', '.').cast('double'))\n",
    "                        .withColumn(\"vl_rem_julho_sc\", regexp_replace(\"vl_rem_julho_sc\", ',', '.').cast('double'))\n",
    "                        .withColumn(\"vl_rem_agosto_sc\", regexp_replace(\"vl_rem_agosto_sc\", ',', '.').cast('double'))\n",
    "                        .withColumn(\"vl_rem_setembro_sc\", regexp_replace(\"vl_rem_setembro_sc\", ',', '.').cast('double'))\n",
    "                        .withColumn(\"vl_rem_outubro_sc\", regexp_replace(\"vl_rem_outubro_sc\", ',', '.').cast('double'))\n",
    "                        .withColumn(\"vl_rem_novembro_sc\", regexp_replace(\"vl_rem_novembro_sc\", ',', '.').cast('double'))\n",
    "                        .drop(\"vl_remun_dezembro__sm\", \"vl_remun_media__sm\")\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2e55bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_display(df, rows):\n",
    "    return df.pandas_api().head(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a5393f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rais2020_fim.createOrReplaceTempView(\"vw_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b19c01dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row</th>\n",
       "      <th>motivo_desligamento</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>9819986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Row  motivo_desligamento    total\n",
       "0    2                   11  9819986"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### 01 - Qual é o SEGUNDO motivo de desligamento mais frequente?\n",
    "func_display(spark.sql(\"\"\"\n",
    "                    WITH seg_desl_mais_freq\n",
    "                    AS (\n",
    "                        SELECT ROW_NUMBER() OVER(ORDER BY COUNT(motivo_desligamento) DESC) AS Row,\n",
    "                            motivo_desligamento,\n",
    "                            count(*) AS total\n",
    "                        FROM vw_df\n",
    "                        GROUP BY motivo_desligamento\n",
    "                        ORDER BY total DESC\n",
    "                        LIMIT 2\n",
    "                    )\n",
    "                    SELECT *\n",
    "                    FROM seg_desl_mais_freq\n",
    "                    WHERE Row = '2'\n",
    "                \"\"\"), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1148594c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    rais2020_fim.write\n",
    "                .format('parquet')\n",
    "                .mode('overwrite')\n",
    "                .partitionBy('ano', 'uf')\n",
    "                .save(pathBronze)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f183be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rais2020_parquet = (\n",
    "                      spark.read\n",
    "                           .format('parquet')\n",
    "                           .load(pathBronze)\n",
    "                   )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a71d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "rais2020_parquet.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e278c29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rais2020_parquet.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a7ee74",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ca9c90c9b299e3c35d28bc96236d8f2c0bd3d51256cb5ad616950692d4a1a879"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
